{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats # for creating a simple dataset \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import one_hot\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from hungarian_algorithm import algorithm\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "stg_path = '../'\n",
    "if stg_path not in sys.path:\n",
    "    sys.path.append(stg_path)\n",
    "\n",
    "from dataset import create_twomoon_dataset\n",
    "from stg import STG, train_net_to_output_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindt = MNIST(\n",
    "    root = 'data',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ")\n",
    "testdt = MNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "\n",
    "tf = transforms.Compose(\n",
    "    [transforms.Normalize((0.1307,), (0.3081,)), transforms.Pad(2)]\n",
    ")\n",
    "\n",
    "\n",
    "X_train = tf(torch.unsqueeze((traindt.data/255).float(), 1))\n",
    "y_train = traindt.targets\n",
    "X_test = tf(torch.unsqueeze((testdt.data/255).float(), 1))\n",
    "y_test = testdt.targets\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if args_cuda else \"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection = True\n",
    "model = STG(task_type='encoding_unet',input_dim=X_train.shape[1], output_dim=20, hidden_dims=32, activation='none',\n",
    "    optimizer='SGD', learning_rate=0.01, batch_size=128, feature_selection=feature_selection, sigma=1, lam=0.001, random_state=1, device=device, extra_args={'gating_net_hidden_dims':[50], 'noise_sigma':0, 'lam_sim': 0.5}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gating_net = model._model.FeatureSelector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_gating_input = torch.randn((10,64), device = device)\n",
    "res_gating = gating_net(rand_gating_input)[0]\n",
    "print('mean output', res_gating.mean().item(), '>0 =0 <0 percentage', (res_gating>0).sum().item()/640, (res_gating==0).sum().item()/640, (res_gating<0).sum().item()/640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_net_to_output_float(gating_net, 0.9, device, (32,64), 10000, 0.1)\n",
    "train_net_to_output_float(gating_net, 0.9, device, (32,64), 10000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gating = gating_net(rand_gating_input)[0]\n",
    "print('mean output', res_gating.mean().item(), '>0 =0 <0 percentage', (res_gating>0).sum().item()/640, (res_gating==0).sum().item()/640, (res_gating<0).sum().item()/640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, None, nr_epochs=1, valid_X=X_test, valid_y=y_test, print_interval=1, is_tensor_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size=5\n",
    "aaa = X_test[0:sample_size]\n",
    "aaa_noise = torch.randn_like(aaa) * 0 + aaa\n",
    "res = model.predict(aaa_noise)\n",
    "\n",
    "fig, axs = plt.subplots(sample_size, 5);\n",
    "fig.set_size_inches(20, 4*sample_size);\n",
    "\n",
    "for i in range(sample_size):\n",
    "    axs[i,0].imshow(res[i].squeeze());\n",
    "    axs[i,1].imshow(aaa_noise.squeeze()[i]);\n",
    "    axs[i,2].imshow(aaa.squeeze()[i]);\n",
    "    axs[i,3].imshow(np.abs(res[i]-aaa[i].numpy())[0]);\n",
    "    axs[i,4].imshow(torch.abs(aaa_noise[i]-aaa[i])[0]);\n",
    "\n",
    "\n",
    "# np.abs(res[0]-aaa[0].numpy()).mean(), torch.abs(aaa_noise[0]-aaa[0]).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=50\n",
    "test_res = model._model.get_gates(\"prob\",X_test[:r].cuda())\n",
    "vals = test_res>0\n",
    "for k in range(10):\n",
    "    print(k)\n",
    "    for i in range(r):\n",
    "        if y_test[i]==k:\n",
    "            print (y_test[i], vals[i].nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(64), vals.astype(int).sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_loss(x):\n",
    "    x_T = x.T\n",
    "\n",
    "    x_norm = torch.linalg.norm(x, dim=1, keepdim=True)  # Size (n, 1).\n",
    "    x_T_norm = torch.linalg.norm(x_T, dim=0, keepdim=True)  # Size (1, b).\n",
    "\n",
    "    cosine_similarity = ((x @ x_T) / (x_norm @ x_T_norm)).T\n",
    "    # cosine_similarity = cosine_similarity - torch.eye(x.size(0), device = x.device)\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy=similarity_loss(torch.from_numpy(test_res))\n",
    "plt.imshow(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = model.get_dataloader(X_test,y_test, False, True)\n",
    "all_res = []\n",
    "for b in test_data_loader:\n",
    "    one_res = (model._model.get_gates(\"prob\",b['input'].cuda())>1e-5).astype(int)\n",
    "    all_res.append(one_res)\n",
    "all_res = np.vstack(all_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cl = AgglomerativeClustering(10, affinity= \"l1\", linkage=\"complete\")\n",
    "cl.fit(all_res)\n",
    "# for i in range(10):\n",
    "#     print(np.where(cl.labels_==i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cl.labels_,bins=cl.n_clusters);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches(a1, a2):\n",
    "    a1_map = {i:np.where(a1==i) for i in range(cl.n_clusters)}\n",
    "    a2_map = {i:np.where(a2==i) for i in range(10)}\n",
    "    scores={}\n",
    "    scores_m = np.zeros((cl.n_clusters, 10))\n",
    "    # scores = np.zeros((len(a1_map), len(a2_map)))\n",
    "    for i in range(cl.n_clusters):\n",
    "        scores[str(i)] = {}\n",
    "        for j in range(10):\n",
    "            val = len(np.intersect1d(a1_map[i], a2_map[j]))\n",
    "            scores[str(i)][\"a\"+str(j)] = val\n",
    "            scores_m[i,j] = val\n",
    "            # scores[i,j]=len(np.intersect1d(a1_map[i], a2_map[j]))\n",
    "    \n",
    "    # return scores_m\n",
    "    \n",
    "    # row_ind, col_ind = linear_sum_assignment(scores)\n",
    "    # return row_ind, col_ind, scores\n",
    "\n",
    "    res=algorithm.find_matching(scores, matching_type = 'max', return_type = 'list' )\n",
    "    return res, sum([r[1] for r in res]), scores_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_res, sums, scores = get_matches(cl.labels_, y_test.numpy())\n",
    "print(sums/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in range(10):\n",
    "    ind = np.where(y_test[:50]==label)\n",
    "    if len(ind[0])==0:\n",
    "        continue\n",
    "    print(label, '\\t', (yy[ind][:,ind].sum(0).min()/len(ind[0])).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 9\n",
    "ind = np.where(y_test[:50]==label)\n",
    "sim_on_label = yy[ind][:,ind].squeeze()\n",
    "sns.heatmap(sim_on_label, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_on_label.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_vals = vals[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(rel_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size=len(ind[0])\n",
    "aaa = X_test[ind]\n",
    "aaa_noise = torch.randn_like(aaa) * 1 + aaa\n",
    "res = model.predict(aaa_noise)\n",
    "\n",
    "fig, axs = plt.subplots(sample_size, 5);\n",
    "fig.set_size_inches(20, 4*sample_size);\n",
    "\n",
    "for i in range(sample_size):\n",
    "    axs[i,0].imshow(res[i].squeeze());\n",
    "    axs[i,1].imshow(aaa_noise.squeeze()[i]);\n",
    "    axs[i,2].imshow(aaa.squeeze()[i]);\n",
    "    axs[i,3].imshow(np.abs(res[i]-aaa[i].numpy())[0]);\n",
    "    axs[i,4].imshow(torch.abs(aaa_noise[i]-aaa[i])[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals[ind].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rel_vals.sum(0)==1).sum(), rel_vals[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_of_interest = np.where((rel_vals.sum(0)==1) & rel_vals[0])\n",
    "indices_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_batch = X_test[np.where(y_test==9)][5:200]\n",
    "print(len(second_batch))\n",
    "\n",
    "second_batch_res = model._model.get_gates(\"prob\",second_batch.cuda())\n",
    "second_batch_vals = second_batch_res>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(second_batch_vals.shape[0]):\n",
    "    inter_score = len( np.intersect1d(np.where(second_batch_vals[i]), indices_of_interest))\n",
    "    if inter_score>=5:\n",
    "        count+=1\n",
    "        print(i,  inter_score)\n",
    "        plt.figure()\n",
    "        plt.imshow(second_batch[i].squeeze())\n",
    "        if count >= 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(second_batch_vals.shape[0]):\n",
    "    inter_score = len( np.intersect1d(np.where(second_batch_vals[i]), indices_of_interest))\n",
    "    if inter_score ==0:\n",
    "        count += 1\n",
    "        print(i,  inter_score)\n",
    "        plt.figure()\n",
    "        plt.imshow(second_batch[i].squeeze())\n",
    "        if count >=5:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_batch_diff = X_test[np.where(y_test!=9)][5:200]\n",
    "print(len(second_batch_diff))\n",
    "\n",
    "second_batch_diff_res = model._model.get_gates(\"prob\",second_batch_diff.cuda())\n",
    "second_batch_diff_vals = second_batch_diff>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(second_batch_diff.shape[0]):\n",
    "    inter_score = len( np.intersect1d(np.where(second_batch_diff_vals[i]), indices_of_interest))\n",
    "    if inter_score >=2:\n",
    "        count += 1\n",
    "        print(i, inter_score)\n",
    "        plt.figure()\n",
    "        plt.imshow(second_batch_diff[i].squeeze())\n",
    "        if count >=5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "lams = [0.2,0.05,0.01,0.005,0.001]\n",
    "lam_sims = [10,2,0.5,0.1,0.02,0.005]\n",
    "for el in product(lams, lam_sims):\n",
    "    print('lam ', el[0], ' lam_sim', el[1])\n",
    "    print('------------------------------------')\n",
    "    feature_selection = True\n",
    "    model = STG(task_type='encoding_unet',input_dim=X_train.shape[1], output_dim=20, hidden_dims=32, activation='none', \n",
    "                optimizer='SGD', learning_rate=0.01, batch_size=128, feature_selection=feature_selection, sigma=1, lam=el[0], random_state=1, device=device, extra_args={'gating_net_hidden_dims':[200,200], 'noise_sigma':1, 'lam_sim': el[1]}) \n",
    "    model.fit(X_train, None, nr_epochs=15, valid_X=X_test, valid_y=y_test, print_interval=1, is_tensor_input=True)\n",
    "    r=50\n",
    "    test_res = model._model.get_gates(\"prob\",X_test[:r].cuda())\n",
    "    plt.figure()\n",
    "    yy=similarity_loss(torch.from_numpy(test_res))\n",
    "    plt.imshow(yy)\n",
    "    plt.title('lam '+str(el[0])+' lam_sim ' + str(el[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "for i in range(10):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = model._model.get_gates('prob', X_test.float().cuda()).reshape(-1,28,28)\n",
    "prob_means = prob.mean(0)\n",
    "plt.imshow(prob_means)\n",
    "prob_fixed = (prob_means > 0.99).astype(float)\n",
    "plt.figure()\n",
    "plt.imshow(prob_fixed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(y_train[i].item())\n",
    "    plt.figure()\n",
    "    plt.imshow(prob[i]-prob_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.figure()\n",
    "    plt.imshow(prob[y_test==i].mean(0)-prob_fixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per digits example and distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    f = plt.figure(figsize=(25,4));\n",
    "    f.suptitle(f'Data distribution for digit {i}',fontsize=16)5\n",
    "    ax1 = f.add_subplot(151)\n",
    "    ax2 = f.add_subplot(152)\n",
    "    ax3 = f.add_subplot(153)\n",
    "    ax4 = f.add_subplot(154)\n",
    "    ax5 = f.add_subplot(155)\n",
    "    # fig, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "    filtered_prob = prob[(y_test==i)]\n",
    "    counts = (filtered_prob > 0.001).sum(1).sum(1)\n",
    "    num_prob = filtered_prob.mean(0)\n",
    "    im = ax3.imshow(num_prob, interpolation='None')\n",
    "    f.colorbar(im, ax=ax3)\n",
    "    ax3.title.set_text('Mean prob')\n",
    "    num_prob = num_prob[num_prob > 0.001]\n",
    "    ax1.hist(num_prob.reshape(-1));\n",
    "    ax1.title.set_text('Mean probability > 0.001 hist')\n",
    "    ax2.hist(counts)\n",
    "    ax2.title.set_text('Number of point > 0.001 hist')\n",
    "    ax4.imshow(X_test[y_test==i][0].reshape(28,28))\n",
    "    ax4.title.set_text('Sample digit')\n",
    "    ax5.imshow(filtered_prob[0].reshape(28,28))\n",
    "    ax5.title.set_text('Sample gates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average gate probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(prob.mean(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = model._model.FeatureSelector.net.mlp[0](X_test[:124].float().cuda()).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = aa[y_test[:124]==0]\n",
    "different = aa[y_test[:124]!=0][:len(similar)]\n",
    "len(similar), len(different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "d1 = distance_matrix(similar, similar, 1)\n",
    "d2 = distance_matrix(similar, different, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.mean(), d2.mean() * (len(d2) - 1)/ len(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
